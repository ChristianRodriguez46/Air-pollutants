# ------------------------------
# Load necessary libraries
# ------------------------------
```{r}
library(dplyr)       # For data manipulation
library(tidyr)       # For data tidying
library(lubridate)   # For date and time manipulation
library(ggplot2)     # For plotting
library(reshape2)
library(car)
library(stats)
```

# ------------------------------
# Step 1: Read and Combine PM2.5 Data Files
# ------------------------------
```{r}
# Define a vector of PM2.5 data file names
file_names <- c('Pm2.5-2018.csv',
                'Pm2.5-2019.csv',
                'Pm2.5-2020.csv',
                'Pm2.5-2021.csv',
                'Pm2.5-2022.csv')

# Read each CSV file into a list and combine them
pm25_data_list <- lapply(file_names, function(file) {
  read.csv(file, stringsAsFactors = FALSE)
})
pm25_data <- bind_rows(pm25_data_list)
```

# ------------------------------
# Step 2: Select and Rename Relevant Columns
# ------------------------------
```{r}
pm25_selected <- pm25_data %>%
  select(Date, 'Daily.Mean.PM2.5.Concentration', County) %>%
  rename(pm2.5 = 'Daily.Mean.PM2.5.Concentration')
```

# ------------------------------
# Step 3: Convert Date Column and Filter Date Range (2018-2022)
# ------------------------------
```{r}
pm25_selected$Date <- as.Date(pm25_selected$Date, format = "%m/%d/%Y")
pm25_filtered_date <- pm25_selected %>%
  filter(Date >= as.Date("2018-01-01") & Date <= as.Date("2022-12-31")) %>%
  group_by(County, Date) %>%
  summarize(pm2.5 = mean(pm2.5, na.rm = TRUE), .groups = "drop")
```

# ------------------------------
# Step 4: Remove Counties with >20% Missing Data
# ------------------------------
```{r}
missing_values <- pm25_filtered_date %>%
  group_by(County) %>%
  summarise(
    Total_Observations = n(),
    Missing_PM25 = sum(is.na(pm2.5)),
    Percent_Missing = (Missing_PM25 / Total_Observations) * 100
  ) %>%
  arrange(desc(Percent_Missing))

print(missing_values)

# Define the threshold (80% of 1826 observations for 5 years)
threshold <- 1826 * 0.80
counties_below_threshold <- missing_values %>%
  filter(Total_Observations < threshold) %>%
  select(County)
counties_to_remove <- counties_below_threshold$County

pm25_filtered_date <- pm25_filtered_date %>%
  filter(!County %in% counties_to_remove)
head(pm25_filtered_date)
```

# ------------------------------
# Step 5: Create Time Variables
# ------------------------------
```{r}
pm25_filtered_date <- pm25_filtered_date %>%
  mutate(
    Week = isoweek(Date),
    SemiMonth = paste(year(Date), month(Date), ifelse(day(Date) <= 15, '1', '2'), sep = '-'),
    Month = month(Date),
    Year = year(Date)
  )

# (The following county-level aggregations you already have:)
weekly_means_filtered <- pm25_filtered_date %>%
  group_by(County, Year, Week) %>%
  summarise(Weekly_Mean = mean(pm2.5, na.rm = TRUE), .groups = 'drop')

semimonthly_means_filtered <- pm25_filtered_date %>%
  group_by(County, SemiMonth) %>%
  summarise(SemiMonthly_Mean = mean(pm2.5, na.rm = TRUE), .groups = 'drop')

monthly_means <- pm25_filtered_date %>%
  group_by(County, Year, Month) %>%
  summarise(Monthly_Mean = mean(pm2.5, na.rm = TRUE), .groups = 'drop')

overall_means_filtered <- pm25_filtered_date %>%
  group_by(County) %>%
  summarise(Overall_Mean = mean(pm2.5, na.rm = TRUE), .groups = 'drop')

head(weekly_means_filtered)
head(semimonthly_means_filtered)
head(monthly_means)
head(overall_means_filtered)
```

# ------------------------------
# Step 6: Read and Process Median Income Data
# ------------------------------
```{r}
median_income <- read.csv('calimedianincome.csv', stringsAsFactors = FALSE) %>%
  mutate(County = trimws(County))
AMI <- 91905  # Area Median Income for California
median_income <- median_income %>%
  mutate(AMI_Multiple = Median_Income / AMI)
num_groups <- 4  # 4 income groups (quartiles)
quantile_probs <- seq(0, 1, length.out = num_groups + 1)
income_quantiles <- quantile(median_income$AMI_Multiple, probs = quantile_probs, na.rm = TRUE)
income_group_labels <- c("Low Income", "Lower Middle Income", "Upper Middle Income", "Upper Income")
median_income <- median_income %>%
  mutate(
    Income_Group = case_when(
      AMI_Multiple <= income_quantiles[2] ~ income_group_labels[1],
      AMI_Multiple > income_quantiles[2] & AMI_Multiple <= income_quantiles[3] ~ income_group_labels[2],
      AMI_Multiple > income_quantiles[3] & AMI_Multiple <= income_quantiles[4] ~ income_group_labels[3],
      AMI_Multiple > income_quantiles[4] ~ income_group_labels[4],
      TRUE ~ NA_character_
    )
  ) %>%
  select(-AMI_Multiple)

median_income_summary <- median_income %>%
  group_by(Income_Group) %>%
  summarise(
    Median_of_Median_Income = median(Median_Income, na.rm = TRUE),
    Count = n()
  ) %>%
  arrange(desc(Count))
print(median_income_summary)
```

# ------------------------------
# Step 7: Read and Process Population Data
# ------------------------------
```{r}
population_files <- list(
  under_18 = 'calipopn(under 18).csv',
  age_18_39 = 'calipopn(18-39).csv',
  age_40_over = 'calipopn(40-over).csv'
)

pop_under_18 <- read.csv(population_files$under_18, stringsAsFactors = FALSE)
names(pop_under_18)[names(pop_under_18) == "X...County"] <- "County"

pop_18_39 <- read.csv(population_files$age_18_39, stringsAsFactors = FALSE)
names(pop_18_39)[names(pop_18_39) == "X...County"] <- "County"

pop_40_over <- read.csv(population_files$age_40_over, stringsAsFactors = FALSE)
names(pop_40_over)[names(pop_40_over) == "X...County"] <- "County"

clean_population_data <- function(df, age_group_col) {
  df <- df %>%
    mutate(
      County = gsub(" County$", "", County),
      County = trimws(County)
    ) %>%
    select(County, !!sym(age_group_col))
  return(df)
}

pop_under_18 <- clean_population_data(pop_under_18, "People..Age.Under.18.") %>%
  rename(People_Under_18 = `People..Age.Under.18.`)
pop_18_39 <- clean_population_data(pop_18_39, "People..Age.18.39.") %>%
  rename(People_18_39 = `People..Age.18.39.`)
pop_40_over <- clean_population_data(pop_40_over, "People..Age.40.And.Over.") %>%
  rename(People_40_Over = `People..Age.40.And.Over.`)

population_data <- pop_under_18 %>%
  left_join(pop_18_39, by = "County") %>%
  left_join(pop_40_over, by = "County") %>%
  mutate(population = People_Under_18 + People_18_39 + People_40_Over) %>%
  select(County, population)
print(head(population_data))
```

# ------------------------------
# Step 8: Clean County Names for Consistency
# ------------------------------
```{r}
pm25_filtered_date$County <- trimws(pm25_filtered_date$County)
median_income$County <- gsub(" County$", "", median_income$County) %>% trimws()

# Check for mismatches
county_mismatches_filtered_mi <- setdiff(unique(pm25_filtered_date$County), unique(median_income$County))
if(length(county_mismatches_filtered_mi) > 0) {
  print("Counties in PM2.5 data not found in median income data:")
  print(county_mismatches_filtered_mi)
} else {
  print("All counties in PM2.5 data are present in median income data.")
}

county_mismatches_filtered_pop <- setdiff(unique(pm25_filtered_date$County), unique(population_data$County))
if(length(county_mismatches_filtered_pop) > 0) {
  print("Counties in PM2.5 data not found in population data:")
  print(county_mismatches_filtered_pop)
} else {
  print("All counties in PM2.5 data are present in population data.")
}
```

# ------------------------------
# Step 9: Merge Data for Disparity Analysis
# ------------------------------
```{r}
analysis_data_filtered <- overall_means_filtered %>%
  left_join(median_income, by = 'County') %>%
  left_join(population_data, by = 'County')

if(sum(is.na(analysis_data_filtered$Income_Group)) > 0) {
  warning("Some counties have missing Income_Group after merging.")
} else {
  print("All counties have associated Income_Group.")
}

pm25_by_income_group_filtered <- analysis_data_filtered %>%
  group_by(Income_Group) %>%
  summarise(
    Weighted_Mean_PM25 = sum(Overall_Mean * population, na.rm = TRUE) / sum(population, na.rm = TRUE),
    Total_Population = sum(population, na.rm = TRUE)
  ) %>%
  arrange(desc(Income_Group))
print(pm25_by_income_group_filtered)
```

# (Existing plotting code follows here ...)
# [Your ggplot2 code for bar plots, scatter plots, etc.]

# ------------------------------
# Additional Analysis: Aggregation by Income Group Over Time
# ------------------------------
```{r}
# Merge daily PM2.5 data with income group information
daily_pm25_income <- pm25_filtered_date %>%
  left_join(median_income %>% select(County, Income_Group), by = "County")

# --- Daily Aggregation ---
daily_income_avg <- daily_pm25_income %>%
  group_by(Income_Group, Date) %>%
  summarize(Daily_Avg_PM25 = mean(pm2.5, na.rm = TRUE), .groups = "drop")

# --- Weekly Aggregation ---
weekly_income_avg <- daily_income_avg %>%
  mutate(Year = year(Date), Week = isoweek(Date)) %>%
  group_by(Income_Group, Year, Week) %>%
  summarize(Weekly_Avg_PM25 = mean(Daily_Avg_PM25, na.rm = TRUE), .groups = "drop")

# --- Biweekly Aggregation ---
daily_income_avg <- daily_income_avg %>%
  mutate(Biweek = as.integer((yday(Date) - 1) %/% 14) + 1, 
         Year = year(Date))
biweekly_income_avg <- daily_income_avg %>%
  group_by(Income_Group, Year, Biweek) %>%
  summarize(Biweekly_Avg_PM25 = mean(Daily_Avg_PM25, na.rm = TRUE), .groups = "drop")

# --- Monthly Aggregation ---
monthly_income_avg <- daily_income_avg %>%
  mutate(Month = month(Date)) %>%
  group_by(Income_Group, Year, Month) %>%
  summarize(Monthly_Avg_PM25 = mean(Daily_Avg_PM25, na.rm = TRUE), .groups = "drop")
```

# ------------------------------
# Coefficient of Divergence (COD)
# ------------------------------

```{r}
# ------------------------------
# Coefficient of Divergence (COD) Matrix and Heatmap for Income Groups
# ------------------------------

# We'll use the aggregated data from the disparity analysis.
# 'pm25_by_income_group_filtered' should contain a column 'Weighted_Mean_PM25' for each Income_Group.
# If you haven't already, check that it looks similar to:
# Income_Group         Weighted_Mean_PM25   Total_Population  Percentage
# "Upper Income"       12.3                 ...
# "Upper Middle Income" 15.4                ...
# etc.

# Create a summary data frame with one PM2.5 value per income group.
income_summary <- pm25_by_income_group_filtered %>%
  dplyr::select(Income_Group, Weighted_Mean_PM25) %>%
  dplyr::rename(mean_pm25 = Weighted_Mean_PM25)

print(income_summary)

# Define a function to calculate the pairwise COD matrix.
calculate_cod_matrix <- function(data) {
  n <- nrow(data)
  cod_matrix <- matrix(0, n, n)
  colnames(cod_matrix) <- data$Income_Group
  rownames(cod_matrix) <- data$Income_Group
  
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      diff <- abs(data$mean_pm25[i] - data$mean_pm25[j])
      sum_ab <- data$mean_pm25[i] + data$mean_pm25[j]
      cod_value <- ifelse(sum_ab == 0, NA, diff / sum_ab)
      cod_matrix[i, j] <- cod_value
      cod_matrix[j, i] <- cod_value
    }
  }
  return(cod_matrix)
}

# Calculate the COD matrix using the income_summary data.
cod_matrix <- calculate_cod_matrix(income_summary)
print(cod_matrix)

# Reshape the COD matrix into a long format data frame for ggplot2.
cod_df <- melt(cod_matrix)
colnames(cod_df) <- c("Income_Group1", "Income_Group2", "COD")
head(cod_df)

# Plot the COD matrix as a heatmap.
ggplot(cod_df, aes(x = Income_Group1, y = Income_Group2, fill = COD)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "white", high = "blue", na.value = "grey80") +
  labs(
    title = "Coefficient of Divergence Matrix by Income Group",
    x = "Income Group",
    y = "Income Group",
    fill = "COD"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

# ------------------------------
# Pearson's Correlation Matrix
# ------------------------------

```{r}
# ------------------------------
# Pearson's Correlation Matrix and Heatmap for Income Groups
# ------------------------------

# (Assuming you have your daily_wide data frame, which was created by pivoting daily_income_avg.
#  It should have one row per day and one column for each income group (e.g., "Low Income", 
#  "Lower Middle Income", "Upper Middle Income", "Upper Income").)

daily_wide <- daily_income_avg %>%
  pivot_wider(names_from = Income_Group, values_from = Daily_Avg_PM25)

# Specify the income group columns (adjust these names if they differ in your data)
income_group_cols <- c("Low Income", "Lower Middle Income", "Upper Middle Income", "Upper Income")

# Compute Pearson's correlation matrix among income groups using complete observations
cor_matrix <- cor(daily_wide %>% dplyr::select(all_of(income_group_cols)), use = "complete.obs")
print(cor_matrix)

# Reshape the correlation matrix to a long-format data frame for ggplot2
cor_df <- melt(cor_matrix)
colnames(cor_df) <- c("Income_Group1", "Income_Group2", "Correlation")
head(cor_df)

# Plot the correlation matrix as a heatmap
ggplot(cor_df, aes(x = Income_Group1, y = Income_Group2, fill = Correlation)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name = "Pearson\nCorrelation") +
  labs(
    title = "Pearson's Correlation Matrix among Income Groups",
    x = "Income Group",
    y = "Income Group"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

```

# ------------------------------
# ANOVA: Testing Differences in Daily PM2.5 by Income Group
# ------------------------------
```{r}
# ---------- Daily ANOVA Assumptions ----------
anova_daily <- aov(Daily_Avg_PM25 ~ Income_Group, data = daily_income_avg)
daily_resid <- resid(anova_daily)
ks_daily <- ks.test(daily_resid, "pnorm", mean = mean(daily_resid), sd = sd(daily_resid))
levene_daily <- leveneTest(Daily_Avg_PM25 ~ Income_Group, data = daily_income_avg)
cat("Daily ANOVA Assumptions:\n")
print(ks_daily)
print(levene_daily)

# ---------- Weekly ANOVA Assumptions ----------
anova_weekly <- aov(Weekly_Avg_PM25 ~ Income_Group, data = weekly_income_avg)
weekly_resid <- resid(anova_weekly)
ks_weekly <- ks.test(weekly_resid, "pnorm", mean = mean(weekly_resid), sd = sd(weekly_resid))
levene_weekly <- leveneTest(Weekly_Avg_PM25 ~ Income_Group, data = weekly_income_avg)
cat("\nWeekly ANOVA Assumptions:\n")
print(ks_weekly)
print(levene_weekly)

# ---------- Biweekly ANOVA Assumptions ----------
anova_biweekly <- aov(Biweekly_Avg_PM25 ~ Income_Group, data = biweekly_income_avg)
biweekly_resid <- resid(anova_biweekly)
ks_biweekly <- ks.test(biweekly_resid, "pnorm", mean = mean(biweekly_resid), sd = sd(biweekly_resid))
levene_biweekly <- leveneTest(Biweekly_Avg_PM25 ~ Income_Group, data = biweekly_income_avg)
cat("\nBiweekly ANOVA Assumptions:\n")
print(ks_biweekly)
print(levene_biweekly)

# ---------- Monthly ANOVA Assumptions ----------
anova_monthly <- aov(Monthly_Avg_PM25 ~ Income_Group, data = monthly_income_avg)
monthly_resid <- resid(anova_monthly)
ks_monthly <- ks.test(monthly_resid, "pnorm", mean = mean(monthly_resid), sd = sd(monthly_resid))
levene_monthly <- leveneTest(Monthly_Avg_PM25 ~ Income_Group, data = monthly_income_avg)
cat("\nMonthly ANOVA Assumptions:\n")
print(ks_monthly)
print(levene_monthly)

# Daily ANOVA
anova_daily <- aov(Daily_Avg_PM25 ~ Income_Group, data = daily_income_avg)
print("ANOVA Results for Daily PM2.5 by Income Group:")
print(summary(anova_daily))

# Weekly ANOVA
anova_weekly <- aov(Weekly_Avg_PM25 ~ Income_Group, data = weekly_income_avg)
print("ANOVA Results for Weekly PM2.5 by Income Group:")
print(summary(anova_weekly))

# Biweekly ANOVA
anova_biweekly <- aov(Biweekly_Avg_PM25 ~ Income_Group, data = biweekly_income_avg)
print("ANOVA Results for Biweekly PM2.5 by Income Group:")
print(summary(anova_biweekly))

# Monthly ANOVA
anova_monthly <- aov(Monthly_Avg_PM25 ~ Income_Group, data = monthly_income_avg)
print("ANOVA Results for Monthly PM2.5 by Income Group:")
print(summary(anova_monthly))
```
## The assumptions of normality and homogeneity of variances are violated

# ------------------------------
# Box-Cox Transformation & Assumptions
# ------------------------------
```{r}
# Ensure PM2.5 values are strictly positive (Box-Cox requires positive values)
min_pm25 <- min(daily_income_avg$Daily_Avg_PM25, na.rm = TRUE)
if (min_pm25 <= 0) {
  daily_income_avg$Daily_Avg_PM25 <- daily_income_avg$Daily_Avg_PM25 - min_pm25 + 1
}

# Run Box-Cox transformation to determine the optimal lambda
boxcox_result <- boxCox(aov(Daily_Avg_PM25 ~ Income_Group, data = daily_income_avg), 
                         lambda = seq(-2, 2, by = 0.1))

# Extract the optimal lambda value (the lambda with highest log-likelihood)
optimal_lambda <- boxcox_result$x[which.max(boxcox_result$y)]
cat("Optimal Lambda for Box-Cox Transformation:", optimal_lambda, "\n")

# Apply the transformation based on the optimal lambda
if (optimal_lambda > 0) {
  daily_income_avg$Transformed_PM25 <- daily_income_avg$Daily_Avg_PM25^optimal_lambda
} else {
  daily_income_avg$Transformed_PM25 <- log(daily_income_avg$Daily_Avg_PM25)
}

# Run ANOVA again with transformed data
anova_transformed <- aov(Transformed_PM25 ~ Income_Group, data = daily_income_avg)
summary(anova_transformed)

# Extract residuals from the transformed ANOVA model
transformed_residuals <- resid(anova_transformed)

# ---------- Normality Check: Kolmogorov-Smirnov Test ----------
ks_transformed <- ks.test(transformed_residuals, "pnorm", mean = mean(transformed_residuals), sd = sd(transformed_residuals))
cat("Kolmogorov-Smirnov Test for Normality (Transformed Data):\n")
print(ks_transformed)

# ---------- Homogeneity of Variances Check: Levene's Test ----------
levene_transformed <- leveneTest(Transformed_PM25 ~ Income_Group, data = daily_income_avg)
cat("\nLevene's Test for Homogeneity of Variances (Transformed Data):\n")
print(levene_transformed)

# Create Q-Q plot
qq_plot <- ggplot(data.frame(residuals = transformed_residuals), aes(sample = residuals)) +
  stat_qq() +
  stat_qq_line(color = "red") +
  labs(title = "Q-Q Plot of Transformed Residuals",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles") +
  theme_minimal()

# Print the plot
print(qq_plot)
```

# ------------------------------
# Tukey's Honestly Significant Difference (HSD) Test for Daily ANOVA
# ------------------------------
```{r}
# Perform Tukey's HSD test on the daily ANOVA model
tukey_daily <- TukeyHSD(anova_daily)
print("Tukey's HSD Test for Daily PM2.5 by Income Group:")
print(tukey_daily)

# Optionally, plot the Tukey HSD results
plot(tukey_daily, las = 1, col = "blue")
```


# ------------------------------
# Concentration Index (CI) Calculation for PM2.5
# ------------------------------
```{r}
# ------------------------------
# Compute Fractional Rank and Concentration Index for PM2.5
# ------------------------------

# Ensure analysis_data_filtered contains:
# - 'Median_Income': the county's median income
# - 'Overall_Mean': the county's overall PM2.5 exposure
# - 'population': the county's population (for weighting)
# - 'Income_Group': optional, for further subgroup analysis

# 1. Compute Fractional Rank
analysis_data_filtered <- analysis_data_filtered %>%
  arrange(Median_Income) %>%                              # Order counties from poorest to richest
  mutate(
    rank = rank(Median_Income, ties.method = "first"),    # Rank counties by median income
    total_count = n(),                                    # Total number of counties (N)
    fractional_rank = (rank - 0.5) / total_count           # Fractional rank: (rank - 0.5)/N
  )

# 2. Compute the Population-Weighted Mean PM2.5
# If you don't have a 'population' column, use:
# mu_pm25 <- mean(analysis_data_filtered$Overall_Mean, na.rm = TRUE)
mu_pm25 <- with(analysis_data_filtered, 
                sum(Overall_Mean * population, na.rm = TRUE) / sum(population, na.rm = TRUE))

# 3. Compute the Concentration Index (CI)
# The formula is: CI = (2/Î¼) * cov(Overall_Mean, fractional_rank)
CI_PM25 <- 2 * cov(analysis_data_filtered$Overall_Mean,
                   analysis_data_filtered$fractional_rank,
                   use = "complete.obs") / mu_pm25

# 4. Print the results
cat("Population-weighted Mean PM2.5 (mu):", mu_pm25, "\n")
cat("Concentration Index (CI) for PM2.5:", CI_PM25, "\n")
```
## The negative value indicates that PM2.5 exposure is higher among counties with lower incomes. In other words, poorer counties are experiencing slightly higher levels of PM2.5 pollution compared to richer counties. 


